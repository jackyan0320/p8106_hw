P8106\_hw5\_xy2395
================
Jack Yan
4/22/2019

``` r
library(tidyverse) # data manipulation
library(ISLR) # data source
library(caret) # model tuning

# parallel processing with caret
library(doParallel)
cluster <- makePSOCKcluster(10)
registerDoParallel(cluster)
```

### Data manipulation

Create a training set containing a random sample of 800 observations, and a test set containing the remaining observations. Use set.seed() for reproducible results.

``` r
data(OJ)

oj <-
  as.tibble(OJ) %>% 
  mutate(Store7 = recode(Store7, '1' = 'Yes', '0' = 'No'),
         Store7 = as.numeric(Store7))

#split the data into training and test sets
set.seed(1)
rowTrain <- createDataPartition(y = oj$Purchase,
                                p = 799/1070,
                                list = FALSE)
train_df = oj[rowTrain,]
test_df = oj[-rowTrain,]

dim(train_df)
```

    ## [1] 800  18

``` r
dim(test_df)
```

    ## [1] 270  18

### (a) Linear kernel

Fit a support vector classifier (linear kernel) to the training data with `Purchase` as the response and the other variables as predictors. What are the training and test error rates?

``` r
ctrl <- trainControl(method = "repeatedcv", repeats = 5)
```

``` r
set.seed(1)
svml.fit <- train(Purchase  ~ ., 
                  data = train_df, 
                  method = "svmLinear2",
                  preProcess = c("center", "scale"),
                  tuneGrid = data.frame(cost = exp(seq(-3,-1,len = 40))),
                  trControl = ctrl)
```

``` r
ggplot(svml.fit, highlight = TRUE)
```

![](p8106_hw5_xy2395_files/figure-markdown_github/unnamed-chunk-5-1.png)

``` r
# Training set error rate
mean(predict(svml.fit) != train_df$Purchase)
```

    ## [1] 0.16125

``` r
# Test set error rate
mean(predict(svml.fit, newdata = test_df) != test_df$Purchase)
```

    ## [1] 0.1777778

For linear kernel, the training error rate is 0.16125 and test error rate is 0.1777778.

### (b) Radial kernel

Fit a support vector machine with a radial kernel to the training data. What are the training and test error rates?

``` r
svmr.grid <- expand.grid(C = exp(seq(-4,0,len=10)),
                         sigma = exp(seq(-5,-3,len=20)))
set.seed(1)             
svmr.fit <- train(Purchase~., 
                  data = train_df,
                  method = "svmRadial",
                  preProcess = c("center", "scale"),
                  tuneGrid = svmr.grid,
                  trControl = ctrl)
```

``` r
ggplot(svmr.fit, highlight = TRUE)
```

![](p8106_hw5_xy2395_files/figure-markdown_github/unnamed-chunk-8-1.png)

``` r
# Training set error rate
mean(predict(svmr.fit) != train_df$Purchase)
```

    ## [1] 0.15625

``` r
# Test set error rate
mean(predict(svmr.fit, newdata = test_df) != test_df$Purchase)
```

    ## [1] 0.1666667

For radial kernel, the training error rate is 0.15625 and test error rate is 0.1666667.

### (c) Comparison

Which approach seems to give a better result on this data?

Radial kernel seems better.

``` r
resamp <- resamples(list(svmr = svmr.fit, svml = svml.fit))
bwplot(resamp)
```

![](p8106_hw5_xy2395_files/figure-markdown_github/unnamed-chunk-9-1.png)

The plot shows Kappa and Accuracy of both kernels from cross-validation based on training data. The radial kernel seem to fit the training data better because it has higher distribution of Kappa and Accuracy.

``` r
tibble(kernel = c('linear', 'radial'),
       training_error = c(mean(predict(svml.fit) != train_df$Purchase),
                          mean(predict(svmr.fit) != train_df$Purchase)),
       test_error = c(mean(predict(svml.fit, newdata = test_df) != test_df$Purchase),
                      mean(predict(svmr.fit, newdata = test_df) != test_df$Purchase)))
```

    ## # A tibble: 2 x 3
    ##   kernel training_error test_error
    ##   <chr>           <dbl>      <dbl>
    ## 1 linear          0.161      0.178
    ## 2 radial          0.156      0.167

Above is a summary of the training and test error rate for the linear kernel and radial kernel. The radial kernal has lower training error rate, indicating that it fits the training data better. More importantly, the radial kernal also has lower test error, showing its better prediction accuracy than the linear kernel.

``` r
# linear kernel
confusionMatrix(data = predict(svml.fit, newdata = test_df), 
                reference = test_df$Purchase)
```

    ## Confusion Matrix and Statistics
    ## 
    ##           Reference
    ## Prediction  CH  MM
    ##         CH 144  27
    ##         MM  21  78
    ##                                           
    ##                Accuracy : 0.8222          
    ##                  95% CI : (0.7713, 0.8659)
    ##     No Information Rate : 0.6111          
    ##     P-Value [Acc > NIR] : 4.866e-14       
    ##                                           
    ##                   Kappa : 0.622           
    ##  Mcnemar's Test P-Value : 0.4705          
    ##                                           
    ##             Sensitivity : 0.8727          
    ##             Specificity : 0.7429          
    ##          Pos Pred Value : 0.8421          
    ##          Neg Pred Value : 0.7879          
    ##              Prevalence : 0.6111          
    ##          Detection Rate : 0.5333          
    ##    Detection Prevalence : 0.6333          
    ##       Balanced Accuracy : 0.8078          
    ##                                           
    ##        'Positive' Class : CH              
    ## 

``` r
# radial kernel
confusionMatrix(data = predict(svmr.fit, newdata = test_df), 
                reference = test_df$Purchase)
```

    ## Confusion Matrix and Statistics
    ## 
    ##           Reference
    ## Prediction  CH  MM
    ##         CH 146  26
    ##         MM  19  79
    ##                                           
    ##                Accuracy : 0.8333          
    ##                  95% CI : (0.7834, 0.8758)
    ##     No Information Rate : 0.6111          
    ##     P-Value [Acc > NIR] : 1.681e-15       
    ##                                           
    ##                   Kappa : 0.645           
    ##  Mcnemar's Test P-Value : 0.3711          
    ##                                           
    ##             Sensitivity : 0.8848          
    ##             Specificity : 0.7524          
    ##          Pos Pred Value : 0.8488          
    ##          Neg Pred Value : 0.8061          
    ##              Prevalence : 0.6111          
    ##          Detection Rate : 0.5407          
    ##    Detection Prevalence : 0.6370          
    ##       Balanced Accuracy : 0.8186          
    ##                                           
    ##        'Positive' Class : CH              
    ## 

We also show the confusion matrix for both kernels based on their prediction on the test data. The radial kernel also has higher sensitivity, specificity, PPV, NPV and Kappa compared with the linear kernel. In conclusion, the **radial** kernel seems to give a better result on the data.
